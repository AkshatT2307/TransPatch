{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12055613,"sourceType":"datasetVersion","datasetId":7587385},{"sourceId":12347323,"sourceType":"datasetVersion","datasetId":7783970},{"sourceId":12784978,"sourceType":"datasetVersion","datasetId":8082901},{"sourceId":12817539,"sourceType":"datasetVersion","datasetId":7731313},{"sourceId":12932627,"sourceType":"datasetVersion","datasetId":8183734},{"sourceId":13010796,"sourceType":"datasetVersion","datasetId":8237199},{"sourceId":13046974,"sourceType":"datasetVersion","datasetId":8261761},{"sourceId":14596872,"sourceType":"datasetVersion","datasetId":9323955},{"sourceId":14609936,"sourceType":"datasetVersion","datasetId":9332040},{"sourceId":14612581,"sourceType":"datasetVersion","datasetId":9333827}],"dockerImageVersionId":31259,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"! rm -rf /kaggle/working/TransPatch","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%cd /kaggle/working/","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!git clone --branch ablations --single-branch --repo_name","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cd /kaggle/working/TransPatch","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Loading Dependencies","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport sys\nimport gc\nsys.path.append('/kaggle/working/TransPatch/')\nfrom utils.utils import setup_logging, get_config_from_yaml, process_config, print_config\nfrom dataset.cityscapes import Cityscapes\nfrom metrics.performance import SegmentationMetric\nfrom utils.helper import val_plot\nfrom patch.create import Patch\nfrom pretrained_models.ICNet.icnet import ICNet\nfrom pretrained_models.BisNetV2.model import BiSeNetV2\nfrom pretrained_models.PIDNet.model import PIDNet, get_pred_model\n\n\nimport pickle\nfrom copy import deepcopy\nfrom tqdm import tqdm\nconfig = get_config_from_yaml('/kaggle/working/TransPatch/configs/config.yaml')\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(device)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Preparing Dataloader","metadata":{}},{"cell_type":"markdown","source":"## Cityscapes","metadata":{}},{"cell_type":"code","source":"cityscape_val = Cityscapes(\n          root = config.dataset.root,\n          list_path = config.dataset.val,\n          num_classes = config.dataset.num_classes,\n          multi_scale = False,\n          flip = False,\n          ignore_label = config.train.ignore_label,\n          base_size = config.train.base_size,\n          crop_size = (config.train.height,config.train.width),\n        )\n\nval_dataloader = torch.utils.data.DataLoader(dataset=cityscape_val,\n                                            batch_size=1,\n                                            shuffle=False,\n                                            num_workers=config.train.num_workers,\n                                            pin_memory=config.train.pin_memory,\n                                            drop_last=config.train.drop_last)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## BDD100k","metadata":{}},{"cell_type":"code","source":"# from dataset.bdd100k import BDD100K\n# from torch.utils.data import Subset\n\n# bdd_data = BDD100K(\n#           root = \"/kaggle/input/solesensei_bdd100k/bdd100k_seg/bdd100k/seg/\",\n#           list_path = config.other_dataset.val,\n#           num_classes = 19,\n#           use_color_labels=False,\n#           multi_scale = False,\n#           flip = False,\n#           ignore_label = config.train.ignore_label,\n#           base_size = config.train.base_size,\n#           crop_size = (config.train.height,config.train.width),\n#         )\n\n# small_dataset = Subset(bdd_data, range(32))\n\n# val_dataloader_bdd = torch.utils.data.DataLoader(dataset=small_dataset,\n#                                             batch_size=4,\n#                                             shuffle=False,\n#                                             num_workers=config.train.num_workers,\n#                                             pin_memory=config.train.pin_memory,\n#                                             drop_last=config.train.drop_last)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Loading Models","metadata":{}},{"cell_type":"code","source":"## PIDNet-s\nmodel = torch.load('/kaggle/input/models/PIDNet_S_Cityscapes_test.pt',map_location=device)\npidnet_s = get_pred_model(name = 'pidnet_s', num_classes = 19).to(device)\nif 'state_dict' in model:\n    model = model['state_dict']\nmodel_dict = pidnet_s.state_dict()\nmodel = {k[6:]: v for k, v in model.items() # k[6:] to start after model. in key names\n                    if k[6:] in model_dict.keys()}\n\npidnet_s.load_state_dict(model)\npidnet_s.eval()\nprint('PIDNet-s Model loaded')\n\n## PIDNet-m\nmodel = torch.load('/kaggle/input/models/PIDNet_M_Cityscapes_test.pt',map_location=device)\npidnet_m = get_pred_model(name = 'pidnet_m', num_classes = 19).to(device)\nif 'state_dict' in model:\n    model = model['state_dict']\nmodel_dict = pidnet_m.state_dict()\nmodel = {k[6:]: v for k, v in model.items() # k[6:] to start after model. in key names\n                    if k[6:] in model_dict.keys()}\n\npidnet_m.load_state_dict(model)\npidnet_m.eval()\nprint('PIDNet-m Model loaded')\n\n## PIDNet-l\ntry:\n    model = torch.load('/kaggle/input/pidnet-l-weights/PIDNet_L_Cityscapes_test.pt',\n                       map_location=device)\n    pidnet_l = get_pred_model(name='pidnet_l', num_classes=19).to(device)\n    if 'state_dict' in model:\n        model = model['state_dict']\n    model_dict = pidnet_l.state_dict()\n    model = {k[6:]: v for k, v in model.items() if k[6:] in model_dict.keys()}\n    pidnet_l.load_state_dict(model)\n    pidnet_l.eval()\n    print('PIDNet-L loaded')\nexcept Exception as e:\n    pidnet_l = None\n    print(f'WARNING: PIDNet-L not loaded: {e}')\n\n# ---- metrics for new models ----\nmetric_pidnet_l   = SegmentationMetric(config)\n\n## ICNet\nmodel = torch.load('/kaggle/input/icnet-wts/icnet_resnet50os8_cityscapes.pth',map_location=device)\nicnet = ICNet(nclass = 19).to(device)\nicnet.eval()\nprint('ICNet loaded')\n\n\n## BISNetV1\nmodel = torch.load('/kaggle/input/models/model_final_v1_city_new.pth',map_location=device)\nbisenetv1 = BiSeNetV2(19,aux_mode = 'eval').to(device)\nbisenetv1.load_state_dict(model, strict=False)\nbisenetv1.eval()\nprint('BisNetV1 loaded')\n\n\n## BiseNetV2\nmodel = torch.load('/kaggle/input/models/model_final_v2_city.pth',map_location=device)\nbisenetv2 = BiSeNetV2(19,aux_mode = 'eval').to(device)\nbisenetv2.load_state_dict(model, strict=False)\nbisenetv2.eval()\nprint('BisNetV2 loaded')\n\n\n## segformer from huggingface\nimport os, io, contextlib\nfrom transformers.utils import logging as hf_logging\nfrom transformers import SegformerImageProcessor, SegformerForSemanticSegmentation\n\n# (A) kill progress bars & tokenizers chatter\nos.environ[\"HF_HUB_DISABLE_PROGRESS_BARS\"] = \"1\"\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n\n# (B) silence HF logging completely\nhf_logging.set_verbosity_error()           # or set_verbosity(hf_logging.CRITICAL)\nhf_logging.disable_default_handler()       # prevent adding console handlers\nhf_logging.enable_propagation()            # keep logs from re-adding handlers\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# (C) suppress any stdout/stderr printed during load (belt & suspenders)\nwith contextlib.redirect_stdout(io.StringIO()), contextlib.redirect_stderr(io.StringIO()):\n    processor = SegformerImageProcessor.from_pretrained(\n        \"nvidia/segformer-b5-finetuned-cityscapes-1024-1024\"\n    )\n    segformer = SegformerForSemanticSegmentation.from_pretrained(\n        \"nvidia/segformer-b5-finetuned-cityscapes-1024-1024\"\n    )\n\n\n# segformer = SegformerForSemanticSegmentation.from_pretrained(\"nvidia/segformer-b0-finetuned-cityscapes-1024-1024\").to(device)\n# segformer.eval()\nsegformer.to(device).eval()\nprint(\"segformer loaded\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Testing mIoU on clean image","metadata":{}},{"cell_type":"code","source":"mean_standard = np.array([0.485, 0.456, 0.406],dtype = np.float32)\nstd_standard = np.array([0.229, 0.224, 0.225],dtype = np.float32)\n\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmetric_pidnet_l = SegmentationMetric(config)\nmetric_pidnet_m = SegmentationMetric(config)\nmetric_pidnet_s = SegmentationMetric(config)\nmetric_icnet = SegmentationMetric(config)\nmetric_bisenetv1 = SegmentationMetric(config)\nmetric_bisenetv2 = SegmentationMetric(config)\nmetric_segformer = SegmentationMetric(config)\n\ndata = {}\nfor i in range(1):\n  # patch = patches[pat]\n  metric_pidnet_l.reset()\n  metric_pidnet_m.reset()\n  metric_pidnet_s.reset()\n  metric_icnet.reset()\n  metric_bisenetv1.reset()\n  metric_bisenetv2.reset()\n  metric_segformer.reset()\n  # print(f'Computing for: {pat}')\n  temp = []\n  for iter,batches in tqdm(enumerate(val_dataloader,0)):\n    image_standard,label,_,_,idx = batches\n    label_patched = deepcopy(label)\n    ## adding patch\n    image_standard, label_patched = image_standard.to(device), label_patched.to(device)\n      \n    # image_standard[:,:,y:y_end,x:x_end] = patch\n    # no patching of label at inference time\n    # label_patched[:,y1:y2,x1:x2] = 10\n\n    ##PIDNet-l\n    outputs = pidnet_l(image_standard)\n    size = label.shape\n    output = F.interpolate(\n                  outputs[config.test.output_index_pidnet], size[-2:],\n                  mode='bilinear', align_corners=True\n                          )\n    metric_pidnet_l.update(output, label_patched)\n    \n    ##PIDNet-m\n    outputs = pidnet_m(image_standard)\n    size = label.shape\n    output = F.interpolate(\n                  outputs[config.test.output_index_pidnet], size[-2:],\n                  mode='bilinear', align_corners=True\n                          )\n    metric_pidnet_m.update(output, label_patched)\n\n    ## PIDNet-s\n    outputs = pidnet_s(image_standard)\n    size = label.shape\n    output = F.interpolate(\n                  outputs[config.test.output_index_pidnet], size[-2:],\n                  mode='bilinear', align_corners=True\n                          )\n    metric_pidnet_s.update(output, label_patched)\n\n    ##ICNet\n    outputs = icnet(image_standard)\n    output = outputs[config.test.output_index_icnet]\n    metric_icnet.update(output,label_patched)\n\n    ##BiseNetV2\n    outputs = bisenetv1(image_standard)\n    output = outputs[config.test.output_index_bisenet]\n    metric_bisenetv1.update(output,label_patched)\n    \n    ##BiseNetV2\n    outputs = bisenetv2(image_standard)\n    output = outputs[config.test.output_index_bisenet]\n    metric_bisenetv2.update(output,label_patched)\n\n    #Segformer\n    segformer = SegformerForSemanticSegmentation.from_pretrained(\"nvidia/segformer-b0-finetuned-cityscapes-1024-1024\").to(device)\n    segformer.eval()\n    outputs = segformer(image_standard)\n    del segformer\n    output = F.interpolate(\n                outputs.logits, size[-2:],\n                mode='bilinear', align_corners=True\n            )\n    metric_segformer.update(output,label_patched)\n    \n    del outputs,output,image_standard,label,batches\n    gc.collect()\n    torch.cuda.empty_cache()\n\n  data = [\n      metric_pidnet_s.get()[1],\n      metric_pidnet_m.get()[1],\n      metric_pidnet_l.get()[1],\n      metric_bisenetv1.get()[1],\n      metric_bisenetv2.get()[1],\n      metric_icnet.get()[1],\n      metric_segformer.get()[1]\n  ]\n  print(data)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Loading coordinates and patch","metadata":{}},{"cell_type":"code","source":"sidewalk_coords = pickle.load(open( \"/kaggle/input/pole-val-coords/pole_val_coords.p\", \"rb\" ))\npidnet_s_p = pickle.load(open( \"/kaggle/input/patches-for-ablations-batch-1/Patches/segformer_patch_base.p\", \"rb\" ))[0]\npatches = {\n    'pidnet_s':pidnet_s_p\n}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# testing on patch location","metadata":{}},{"cell_type":"code","source":"mean_standard = np.array([0.485, 0.456, 0.406],dtype = np.float32)\nstd_standard = np.array([0.229, 0.224, 0.225],dtype = np.float32)\nx = (2048 - 200)//2\ny = (1024 - 200)//2\nx_end = x + 200\ny_end = y + 200\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmetric_pidnet_l = SegmentationMetric(config)\nmetric_pidnet_m = SegmentationMetric(config)\nmetric_pidnet_s = SegmentationMetric(config)\nmetric_icnet = SegmentationMetric(config)\nmetric_bisenetv1 = SegmentationMetric(config)\nmetric_bisenetv2 = SegmentationMetric(config)\nmetric_segformer = SegmentationMetric(config)\n\ndata = {}\nfor pat in ['pidnet_s']:\n  patch = patches[pat]\n  metric_pidnet_l.reset()\n  metric_pidnet_m.reset()\n  metric_pidnet_s.reset()\n  metric_icnet.reset()\n  metric_bisenetv1.reset()\n  metric_bisenetv2.reset()\n  metric_segformer.reset()\n  print(f'Computing for: {pat}')\n  temp = []\n  for iter,batches in tqdm(enumerate(val_dataloader,0)):\n    image_standard,label,_,_,idx = batches\n    label_patched = deepcopy(label)\n\n    ## adding patch\n    sidewalk_coords[iter] = sidewalk_coords[iter].to(device)\n    image_standard, label_patched = image_standard.to(device), label_patched.to(device)\n    if(len(sidewalk_coords[iter])!=0):\n        x1, y1, x2, y2 = sidewalk_coords[iter]\n        #self.logger.info(f\"(x1,y1,x2,y2):{x1,y1,x2,y2}, Idx:{idx}, Iter: {i_iter}\")\n        image_standard[:,:,y1:y2,x1:x2] = patch\n        # label_patched[:,y1:y2,x1:x2] = 10\n    \n        ##PIDNet-l\n        outputs = pidnet_l(image_standard)\n        size = label.shape\n        output = F.interpolate(\n                      outputs[config.test.output_index_pidnet], size[-2:],\n                      mode='bilinear', align_corners=True\n                              )\n        metric_pidnet_l.update(output, label_patched)\n        \n        #PIDNet-m\n        outputs = pidnet_m(image_standard)\n        size = label.shape\n        output = F.interpolate(\n                      outputs[config.test.output_index_pidnet], size[-2:],\n                      mode='bilinear', align_corners=True\n                              )\n        metric_pidnet_m.update(output, label_patched)\n    \n        # PIDNet-s\n        outputs = pidnet_s(image_standard)\n        size = label.shape\n        output = F.interpolate(\n                      outputs[config.test.output_index_pidnet], size[-2:],\n                      mode='bilinear', align_corners=True\n                              )\n        metric_pidnet_s.update(output, label_patched)\n    \n        #ICNet\n        outputs = icnet(image_standard)\n        output = outputs[config.test.output_index_icnet]\n        metric_icnet.update(output,label_patched)\n\n        #BiseNetV2\n        outputs = bisenetv1(image_standard)\n        output = outputs[config.test.output_index_bisenet]\n        metric_bisenetv1.update(output,label_patched)\n        \n        #BiseNetV2\n        outputs = bisenetv2(image_standard)\n        output = outputs[config.test.output_index_bisenet]\n        metric_bisenetv2.update(output,label_patched)\n\n        ##Segformer\n        segformer = SegformerForSemanticSegmentation.from_pretrained(\"nvidia/segformer-b0-finetuned-cityscapes-1024-1024\").to(device)\n        segformer.eval()\n        outputs = segformer(image_standard)\n        del segformer\n        output = F.interpolate(\n                    outputs.logits, size[-2:],\n                    mode='bilinear', align_corners=True\n                )\n        metric_segformer.update(output,label_patched)\n        \n        del outputs,output,image_standard,label,batches\n        gc.collect()\n        torch.cuda.empty_cache()\n  data[pat] = [\n      metric_pidnet_s.get()[1],\n      metric_pidnet_m.get()[1],\n      metric_pidnet_l.get()[1],\n      metric_bisenetv1.get()[1],\n      metric_bisenetv2.get()[1],\n      metric_icnet.get()[1],\n      metric_segformer.get()[1]\n  ]\n  print(data[pat])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Testing by placing in center","metadata":{}},{"cell_type":"code","source":"mean_standard = np.array([0.485, 0.456, 0.406],dtype = np.float32)\nstd_standard = np.array([0.229, 0.224, 0.225],dtype = np.float32)\nx = (2048 - 200)//2\ny = (1024 - 200)//2\nx_end = x + 200\ny_end = y + 200\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmetric_pidnet_l = SegmentationMetric(config)\nmetric_pidnet_m = SegmentationMetric(config)\nmetric_pidnet_s = SegmentationMetric(config)\nmetric_icnet = SegmentationMetric(config)\nmetric_bisenetv1 = SegmentationMetric(config)\nmetric_bisenetv2 = SegmentationMetric(config)\nmetric_segformer = SegmentationMetric(config)\n\ndata = {}\nfor pat in ['pidnet_s']:\n  patch = patches[pat]\n  metric_pidnet_l.reset()\n  metric_pidnet_m.reset()\n  metric_pidnet_s.reset()\n  metric_icnet.reset()\n  metric_bisenetv1.reset()\n  metric_bisenetv2.reset()\n  metric_segformer.reset()\n  print(f'Computing for: {pat}')\n  temp = []\n  for iter,batches in tqdm(enumerate(val_dataloader,0)):\n    image_standard,label,_,_,idx = batches\n    label_patched = deepcopy(label)\n    ## adding patch\n    image_standard, label_patched = image_standard.to(device), label_patched.to(device)\n    image_standard[:,:,y:y_end,x:x_end] = patch\n    # label_patched[:,y1:y2,x1:x2] = 10\n\n    ##PIDNet-l\n    outputs = pidnet_l(image_standard)\n    size = label.shape\n    output = F.interpolate(\n                  outputs[config.test.output_index_pidnet], size[-2:],\n                  mode='bilinear', align_corners=True\n                          )\n    metric_pidnet_l.update(output, label_patched)\n    \n    ##PIDNet-m\n    outputs = pidnet_m(image_standard)\n    size = label.shape\n    output = F.interpolate(\n                  outputs[config.test.output_index_pidnet], size[-2:],\n                  mode='bilinear', align_corners=True\n                          )\n    metric_pidnet_m.update(output, label_patched)\n\n    ## PIDNet-s\n    outputs = pidnet_s(image_standard)\n    size = label.shape\n    output = F.interpolate(\n                  outputs[config.test.output_index_pidnet], size[-2:],\n                  mode='bilinear', align_corners=True\n                          )\n    metric_pidnet_s.update(output, label_patched)\n\n    # ##ICNet\n    # outputs = icnet(image_standard)\n    # output = outputs[config.test.output_index_icnet]\n    # metric_icnet.update(output,label_patched)\n\n    ##BiseNetV2\n    outputs = bisenetv1(image_standard)\n    output = outputs[config.test.output_index_bisenet]\n    metric_bisenetv1.update(output,label_patched)\n    \n    ##BiseNetV2\n    outputs = bisenetv2(image_standard)\n    output = outputs[config.test.output_index_bisenet]\n    metric_bisenetv2.update(output,label_patched)\n\n    ##Segformer\n    segformer = SegformerForSemanticSegmentation.from_pretrained(\"nvidia/segformer-b0-finetuned-cityscapes-1024-1024\").to(device)\n    segformer.eval()\n    outputs = segformer(image_standard)\n    del segformer\n    output = F.interpolate(\n                outputs.logits, size[-2:],\n                mode='bilinear', align_corners=True\n            )\n    metric_segformer.update(output,label_patched)\n    \n    del outputs,output,image_standard,label,batches\n    gc.collect()\n    torch.cuda.empty_cache()\n\n  data[pat] = [\n      metric_pidnet_s.get()[1],\n      metric_pidnet_m.get()[1],\n      metric_pidnet_l.get()[1],\n      metric_bisenetv1.get()[1],\n      metric_bisenetv2.get()[1],\n      # metric_icnet.get()[1],\n      metric_segformer.get()[1]\n  ]\n  print(data[pat])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Testing patch on coordinate placement","metadata":{}},{"cell_type":"code","source":"mean_standard = np.array([0.485, 0.456, 0.406],dtype = np.float32)\nstd_standard = np.array([0.229, 0.224, 0.225],dtype = np.float32)\nx = (2048 - 200)//2\ny = (1024 - 200)//2\nx_end = x + 200\ny_end = y + 200\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmetric_pidnet_l = SegmentationMetric(config)\nmetric_pidnet_m = SegmentationMetric(config)\nmetric_pidnet_s = SegmentationMetric(config)\nmetric_icnet = SegmentationMetric(config)\nmetric_bisenetv1 = SegmentationMetric(config)\nmetric_bisenetv2 = SegmentationMetric(config)\nmetric_segformer = SegmentationMetric(config)\n\ndata = {}\nfor pat in ['pidnet_s']:\n  patch = patches[pat]\n  metric_pidnet_l.reset()\n  metric_pidnet_m.reset()\n  metric_pidnet_s.reset()\n  metric_icnet.reset()\n  metric_bisenetv1.reset()\n  metric_bisenetv2.reset()\n  metric_segformer.reset()\n  print(f'Computing for: {pat}')\n  temp = []\n  for iter,batches in tqdm.tqdm(enumerate(val_dataloader,0)):\n    image_standard,label,_,_,idx = batches\n    label_patched = deepcopy(label)\n\n    ## adding patch\n    sidewalk_coords[iter] = sidewalk_coords[iter].to(device)\n    image_standard, label_patched = image_standard.to(device), label_patched.to(device)\n    if(len(sidewalk_coords[iter])!=0):\n        x1, y1, x2, y2 = sidewalk_coords[iter]\n        #self.logger.info(f\"(x1,y1,x2,y2):{x1,y1,x2,y2}, Idx:{idx}, Iter: {i_iter}\")\n        image_standard[:,:,y1:y2,x1:x2] = patch\n        # label_patched[:,y1:y2,x1:x2] = 10\n    \n        ##PIDNet-l\n        outputs = pidnet_l(image_standard)\n        size = label.shape\n        output = F.interpolate(\n                      outputs[config.test.output_index_pidnet], size[-2:],\n                      mode='bilinear', align_corners=True\n                              )\n        metric_pidnet_l.update(output, label_patched)\n        \n        #PIDNet-m\n        outputs = pidnet_m(image_standard)\n        size = label.shape\n        output = F.interpolate(\n                      outputs[config.test.output_index_pidnet], size[-2:],\n                      mode='bilinear', align_corners=True\n                              )\n        metric_pidnet_m.update(output, label_patched)\n    \n        # PIDNet-s\n        outputs = pidnet_s(image_standard)\n        size = label.shape\n        output = F.interpolate(\n                      outputs[config.test.output_index_pidnet], size[-2:],\n                      mode='bilinear', align_corners=True\n                              )\n        metric_pidnet_s.update(output, label_patched)\n    \n        #ICNet\n        outputs = icnet(image_standard)\n        output = outputs[config.test.output_index_icnet]\n        metric_icnet.update(output,label_patched)\n\n        #BiseNetV2\n        outputs = bisenetv1(image_standard)\n        output = outputs[config.test.output_index_bisenet]\n        metric_bisenetv1.update(output,label_patched)\n        \n        #BiseNetV2\n        outputs = bisenetv2(image_standard)\n        output = outputs[config.test.output_index_bisenet]\n        metric_bisenetv2.update(output,label_patched)\n\n        ##Segformer\n        segformer = SegformerForSemanticSegmentation.from_pretrained(\"nvidia/segformer-b0-finetuned-cityscapes-1024-1024\").to(device)\n        segformer.eval()\n        outputs = segformer(image_standard)\n        del segformer\n        output = F.interpolate(\n                    outputs.logits, size[-2:],\n                    mode='bilinear', align_corners=True\n                )\n        metric_segformer.update(output,label_patched)\n        \n        del outputs,output,image_standard,label,batches\n        gc.collect()\n        torch.cuda.empty_cache()\n  data[pat] = [\n      metric_pidnet_s.get()[1],\n      metric_pidnet_m.get()[1],\n      metric_pidnet_l.get()[1],\n      metric_bisenetv1.get()[1],\n      metric_bisenetv2.get()[1],\n      # metric_icnet.get()[1],\n      metric_segformer.get()[1]\n  ]\n  print(data[pat])","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}